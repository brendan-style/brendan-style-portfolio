[
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Insightful Analytics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nPySpark Basics\n\n\n\n\n\n\n\n\nFeb 17, 2025\n\n\nBrendan Style\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\nJan 22, 2025\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nStarwars\n\n\n\n\n\n\n\n\nJan 22, 2025\n\n\nYour Name\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\nJan 22, 2025\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let’s analyze the starwars data:\nstarwars &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs. Droid",
    "text": "Human vs. Droid\n\nggplot(data = \n         starwars %&gt;% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code with no space in the folder name.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brendan Style",
    "section": "",
    "text": "Brendan Style majors in Data Analytics at SUNY Geneseo. While at school, Brendan also spends his time competing as a member of the Geneseo Track and Field Team."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Brendan Style",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo | Geneseo, NY  B.S. in Data Analytics | Aug 2021 - May 2025"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Brendan Style",
    "section": "Experience",
    "text": "Experience\nSUNY Geneseo | Data Analytics Tutor | August 2024 - Current"
  },
  {
    "objectID": "danl_proj_nba.html#salary-distribution-among-teams",
    "href": "danl_proj_nba.html#salary-distribution-among-teams",
    "title": "Data Analysis Project",
    "section": "Salary Distribution Among Teams",
    "text": "Salary Distribution Among Teams\nLet’s start with the salary distribution among teams using seaborn for visualization. ​​\n\n\n# Handle missing values in 'Salary' by replacing them with the median salary\nmedian_salary = nba['Salary'].median()\nnba['Salary'].fillna(median_salary, inplace=True)\n\n/var/folders/_m/d6jf0jhd2zzdfd5kzdhl_24w0000gn/T/ipykernel_79892/1671011424.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  nba['Salary'].fillna(median_salary, inplace=True)\n\n\n\n# Set the aesthetic style of the plots\nsns.set_style(\"whitegrid\")\n\n# Calculate total salary by team\nteam_salary = (\n    nba\n    .groupby('Team')['Salary']\n    .sum()\n    .reset_index()\n    .sort_values(by='Salary', ascending=False)\n)\n\n# Plot total salary by team\nplt.figure(figsize=(10, 16))\nsns.barplot(data = team_salary,\n            x = 'Salary', y = 'Team',\n            palette = 'coolwarm')\nplt.title('Total Salary Distribution Among NBA Teams')\nplt.xlabel('Total Salary')\nplt.ylabel('Team')\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\nThe visualization above displays the total salary distribution among NBA teams, with teams sorted by their total salary expenditure. This bar plot reveals which teams are the biggest spenders on player salaries and which are more conservative. The color gradient provides a visual cue to easily distinguish between the higher and lower spending teams.\nNotice that Portland Trail Blazers has the highest total salary followed by Golden State Warriors and Philadelphia 76ers, and Memphis Grizzlies has the lowest total salary."
  },
  {
    "objectID": "danl_proj_nba.html#player-age-distribution",
    "href": "danl_proj_nba.html#player-age-distribution",
    "title": "Data Analysis Project",
    "section": "Player Age Distribution",
    "text": "Player Age Distribution\nNext, let’s explore the Player Age Distribution across the NBA. We’ll create a histogram to visualize how player ages are distributed, which will help us understand if the league trends younger, older, or has a balanced age mix. ​​\n\n# Convert 'Birthday' column to datetime format\nfrom dateutil import parser\n# nba['Birthday'] = nba['Birthday'].apply(lambda x: parser.parse(x))\n\n# Now, let's calculate the age of each player\n# nba['Age'] = (datetime.now() - nba['Birthday']).dt.days // 365\n\n# Plot the age distribution of NBA players\nplt.figure(figsize=(10, 6))\nsns.histplot(nba['Age'],\n             bins = 15,\n             kde = True,\n             color = 'skyblue')\nplt.title('Age Distribution of NBA Players')\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.show()\n\n\n/Users/bchoe/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n\n\n\n\n\n\n\n\n\nThe histogram above shows the age distribution of NBA players, with a kernel density estimate (KDE) overlay to indicate the distribution shape. The plot helps identify the common ages for NBA players and whether there are significant numbers of very young or older players.\nNotice that the majority of players fall within an age range from 24 to 34. There are few players whose age is above 40."
  },
  {
    "objectID": "danl_proj_nba.html#position-wise-salary-insights",
    "href": "danl_proj_nba.html#position-wise-salary-insights",
    "title": "Data Analysis Project",
    "section": "Position-wise Salary Insights",
    "text": "Position-wise Salary Insights\nMoving on to Position-wise Salary Insights, we’ll examine how average salaries differ across player positions. This analysis could reveal which positions are typically higher-paid, potentially reflecting their value on the basketball court. Let’s create a box plot to visualize the salary distribution for each position. ​​\n\n# Plot salary distribution by player position\nplt.figure(figsize=(10, 6))\nsns.boxplot(data = nba,\n            x = 'Position', y = 'Salary',\n            palette = 'Set2')\nplt.title('Salary Distribution by Position')\nplt.xlabel('Position')\nplt.ylabel('Salary')\nplt.show()\n\n\n\n\n\n\n\n\nThe box plot above illustrates the salary distribution by player position, showcasing the variation in salaries among different positions within the NBA. PG-SG has the highest median salary."
  },
  {
    "objectID": "danl_proj_nba.html#top-10-highest-paid-players",
    "href": "danl_proj_nba.html#top-10-highest-paid-players",
    "title": "Data Analysis Project",
    "section": "Top 10 Highest Paid Players",
    "text": "Top 10 Highest Paid Players\nLastly, we’ll identify the Top 10 Highest Paid Players in the NBA. Let’s visualize this information.\n\n# Identify the top 10 highest paid players\ntop_10_salaries = nba.sort_values(by='Salary', ascending=False).head(10)\n\n# Plot the top 10 highest paid players\nplt.figure(figsize=(12, 8))\nsns.barplot(data = top_10_salaries,\n            x = 'Salary', y = 'PlayerName',\n            palette = 'viridis')\nplt.title('Top 10 Highest Paid NBA Players')\nplt.xlabel('Salary')\nplt.ylabel('Player')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar plot above reveals the top 10 highest-paid NBA players, showcasing those who stand at the pinnacle of the league in terms of salary. This visualization not only highlights the star players who command the highest salaries but also may reflect their marketability, performance, and contribution to their respective teams."
  },
  {
    "objectID": "seaborn_basics.html",
    "href": "seaborn_basics.html",
    "title": "Seaborn Example",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Sample data\ndata = {\n    'Category': ['A', 'B', 'C', 'D'],\n    'Values': [23, 45, 56, 78]\n}\ndf = pd.DataFrame(data)\n\n# Create a barplot\nsns.set(style=\"whitegrid\")  # Optional: Set a clean grid style\nplt.figure(figsize=(8, 6))  # Set the figure size\nsns.barplot(data=df, x='Category', y='Values', palette='viridis')\n\n# Customize the plot\nplt.title(\"Bar Plot Example\", fontsize=16)\nplt.xlabel(\"Category\", fontsize=12)\nplt.ylabel(\"Values\", fontsize=12)\n\n# Show the plot\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(data=df, x='Category', y='Values', palette='viridis')"
  },
  {
    "objectID": "pandas_basics.html#creating-a-series",
    "href": "pandas_basics.html#creating-a-series",
    "title": "Pandas Basics",
    "section": "Creating a Series",
    "text": "Creating a Series\n\n\n# Creating a Series from a list\ndata = [10, 20, 30, 40, 50]\nseries = pd.Series(data)\nseries\n\n\n\n\n\n\n\n\n0\n\n\n\n\n0\n10\n\n\n1\n20\n\n\n2\n30\n\n\n3\n40\n\n\n4\n50\n\n\n\n\ndtype: int64"
  },
  {
    "objectID": "pandas_basics.html#creating-a-dataframe",
    "href": "pandas_basics.html#creating-a-dataframe",
    "title": "Pandas Basics",
    "section": "Creating a DataFrame",
    "text": "Creating a DataFrame\n\n\n# Creating a DataFrame from a dictionary\ndata = {\n    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"Age\": [25, 30, 35],\n    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n}\ndf = pd.DataFrame(data)\ndf\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n0\nAlice\n25\nNew York\n\n\n1\nBob\n30\nLos Angeles\n\n\n2\nCharlie\n35\nChicago"
  },
  {
    "objectID": "pandas_basics.html#exploring-data",
    "href": "pandas_basics.html#exploring-data",
    "title": "Pandas Basics",
    "section": "Exploring Data",
    "text": "Exploring Data\n\n\n# Display the first few rows\ndf.head()\n\n# Display the shape of the DataFrame\nprint(\"Shape:\", df.shape)\n\n# Display summary statistics\ndf.describe()\n\nShape: (3, 3)\n\n\n\n  \n    \n\n\n\n\n\n\nAge\n\n\n\n\ncount\n3.0\n\n\nmean\n30.0\n\n\nstd\n5.0\n\n\nmin\n25.0\n\n\n25%\n27.5\n\n\n50%\n30.0\n\n\n75%\n32.5\n\n\nmax\n35.0"
  },
  {
    "objectID": "pandas_basics.html#selecting-data",
    "href": "pandas_basics.html#selecting-data",
    "title": "Pandas Basics",
    "section": "Selecting Data",
    "text": "Selecting Data\n\n# Selecting a single column\ndf[\"Name\"]\n\n\n\n\n\n\n\n\nName\n\n\n\n\n0\nAlice\n\n\n1\nBob\n\n\n2\nCharlie\n\n\n\n\ndtype: object\n\n\n\n# Selecting multiple columns\ndf[[\"Name\", \"City\"]]\n\n\n  \n    \n\n\n\n\n\n\nName\nCity\n\n\n\n\n0\nAlice\nNew York\n\n\n1\nBob\nLos Angeles\n\n\n2\nCharlie\nChicago\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n# Selecting rows by index\ndf.iloc[0]\n\n\n\n\n\n\n\n\n0\n\n\n\n\nName\nAlice\n\n\nAge\n25\n\n\nCity\nNew York\n\n\n\n\ndtype: object"
  },
  {
    "objectID": "pandas_basics.html#filtering-data",
    "href": "pandas_basics.html#filtering-data",
    "title": "Pandas Basics",
    "section": "Filtering Data",
    "text": "Filtering Data\n\n# Filtering rows where Age is greater than 25\nfiltered_df = df[df[\"Age\"] &gt; 25]\nfiltered_df\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n1\nBob\n30\nLos Angeles\n\n\n2\nCharlie\n35\nChicago"
  },
  {
    "objectID": "pandas_basics.html#adding-a-new-column",
    "href": "pandas_basics.html#adding-a-new-column",
    "title": "Pandas Basics",
    "section": "Adding a New Column",
    "text": "Adding a New Column\n\n\n# Adding a new column\ndf[\"Salary\"] = [50000, 60000, 70000]\ndf\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\nSalary\n\n\n\n\n0\nAlice\n25\nNew York\n50000\n\n\n1\nBob\n30\nLos Angeles\n60000\n\n\n2\nCharlie\n35\nChicago\n70000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n    ## Conclusion\n\n    This notebook covers the basic operations of pandas. You can explore more advanced features like merging,\n    joining, and working with time series data in pandas documentation: https://pandas.pydata.org/docs/"
  },
  {
    "objectID": "posts/pyspark/posts/welcome/index.html",
    "href": "posts/pyspark/posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/pyspark/index.html",
    "href": "posts/pyspark/index.html",
    "title": "pyspark",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 17, 2025\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 14, 2025\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/pyspark/about.html",
    "href": "posts/pyspark/about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/pyspark/posts/post-with-code/index.html",
    "href": "posts/pyspark/posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/PySpark Basics/index.html",
    "href": "posts/PySpark Basics/index.html",
    "title": "PySpark Basics",
    "section": "",
    "text": "This is a blog post explaining some of the basics of Apache Hadoop, Apache Spark, and PySpark that we have learned so far in class.\n\nApache Hadoop\nApache Hadoop was created explicitly to help analysts deal with storing large datasets(usually exceeding 1gb). The primary way it does this is by breaking up the data into blocks and storing those blocks across different servers. This allows for both faster run times, by minimizing data movement through MapReduce, as well as minimizing errors, since, even if one of the blocks fails, the rest can still be altered successfully. The main drawback of Hadoop is that it cannot process events happening in real time, such the fluctuation of stock prices.\n\n\nApache Spark\nApache Spark deals more with the data analysis side of the datasets. It accomplishes these queries of large datasets by utilizing a structure of clusters that able to potentially take big applications and divide them into smaller tasks that take overall less computing power. Though this is a very powerful tool for creating queries, a shortcoming of Spark is a lack of a personal storage system, which is why many will use it in tandem with the storage capabilities of Hadoop, since Spark’s cluster-based method of applying queries was designed for Hadoop’s block storage.\n\n\nPySpark\nPySpark is a Python library that allows the user to run a number of Apache Spark functions on Python. The storage methods oh a pyspark dataframe are similar to what we discussed earlier, with different blocks of data being stored on multiple different machines, which allows for loading datasets and performing queries that may be beyond the capabilities of one device. It optimizes query speed by not actually performing the query until an action is called that makes it necessary, a process referred to as “lazy evaluation”. Another feature of pyspark is the ability to recovery the data if one of these blocks/nodes of data fails at any point."
  },
  {
    "objectID": "posts/welcome/index.html#experience",
    "href": "posts/welcome/index.html#experience",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "#\n\n#\n\nStarbucks Analytics | Data Analyst Intern | May 2024 - Aug 2024\n\nThis is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "great_day.html",
    "href": "great_day.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "great_day/post-with-code/index.html",
    "href": "great_day/post-with-code/index.html",
    "title": "What is GREAT Day?",
    "section": "",
    "text": "This will be a blog with a short write-up about what GREAT day is all about"
  },
  {
    "objectID": "projects/proj_1/index.html",
    "href": "projects/proj_1/index.html",
    "title": "NFL Draft Trends Analyzed and Visualized(Work In Progress)",
    "section": "",
    "text": "This will be a blog post recapping my findings from my project for Geneseo’s GREAT Day in 2024, as a part of my Data Visualization Final Project."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nNFL Draft Trends Analyzed and Visualized(Work In Progress)\n\n\n\n\n\n\n\n\nFeb 25, 2025\n\n\nBrendan Style\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/proj_1/index.html#goals",
    "href": "projects/proj_1/index.html#goals",
    "title": "NFL Draft Trends Analyzed and Visualized(Work In Progress)",
    "section": "Goals",
    "text": "Goals\nWhen beginning this project, I had 3 questions I wanted to answer:\n\nWhat impact does drafting have on overall team success?\nWhat Impact does prior drafting success have on future drafting success?\nHow has the shift in NFL playstyle impacted overall draft strategy?"
  },
  {
    "objectID": "projects/proj_1/index.html#dataset-acquisitioncleaning-and-variable-creation",
    "href": "projects/proj_1/index.html#dataset-acquisitioncleaning-and-variable-creation",
    "title": "NFL Draft Trends Analyzed and Visualized",
    "section": "Dataset Acquisition/Cleaning and Variable Creation",
    "text": "Dataset Acquisition/Cleaning and Variable Creation"
  },
  {
    "objectID": "projects/proj_1/index.html#dataset-acquisitioncleaning",
    "href": "projects/proj_1/index.html#dataset-acquisitioncleaning",
    "title": "NFL Draft Trends Analyzed and Visualized",
    "section": "Dataset Acquisition/Cleaning",
    "text": "Dataset Acquisition/Cleaning\nCreation of the dataset was quite simple. Thanks to the draft library from nfl-data-py, I was able to load all NFL draft selections from 1980 onward into a python pandas dataframe."
  },
  {
    "objectID": "projects/proj_1/index.html#dataset",
    "href": "projects/proj_1/index.html#dataset",
    "title": "NFL Draft Trends Analyzed and Visualized(Work In Progress)",
    "section": "Dataset",
    "text": "Dataset\n\nAcquisition\nCreation of the dataset was quite simple. Thanks to the draft library from nfl-data-py, I was able to load all NFL draft selections beginning in 1980 into a dataframe, which I have provided a snapshot of below.\n\n\n\n\n\nseason\nround\npick\npfr_player_name\nposition\nw_av\n\n\n\n\n1987\n1\n10\nRod Woodson\nDB\n142\n\n\n1997\n1\n13\nTony Gonzalez\nTE\n95\n\n\n1985\n1\n16\nJerry Rice\nWR\n160\n\n\n1996\n1\n26\nRay Lewis\nLB\n160\n\n\n1985\n1\n1\nBruce Smith\nDE\n152\n\n\n1989\n1\n5\nDeion Sanders\nDB\n127\n\n\n2013\n3\n63\nTravis Kelce\nTE\n86\n\n\n1981\n1\n2\nLawrence Taylor\nLB\n146\n\n\n1981\n1\n8\nRonnie Lott\nDB\n123\n\n\n1994\n1\n2\nMarshall Faulk\nRB\n132\n\n\n1995\n1\n28\nDerrick Brooks\nLB\n142\n\n\n1983\n1\n9\nBruce Matthews\nG\n138\n\n\n1990\n1\n17\nEmmitt Smith\nRB\n129\n\n\n2001\n1\n5\nLaDainian Tomlinson\nRB\n129\n\n\n1990\n7\n192\nShannon Sharpe\nTE\n82\n\n\n1999\n1\n7\nChamp Bailey\nDB\n117\n\n\n2003\n3\n69\nJason Witten\nTE\n80\n\n\n1998\n1\n4\nCharles Woodson\nDB\n115\n\n\n1990\n1\n5\nJunior Seau\nLB\n133\n\n\n2010\n2\n42\nRob Gronkowski\nTE\n78\n\n\n\n\n\nAll told this dataset comes in at well over 10,000 observations, and provides much more data about the players than what is shown above. Things like career stats/accolades, college attended, etc.\n\n\nCleaning\nSince this research is attempting to overall career value as the main metric, it would be unfair to incorperate recent draft classes, since they haven’t had enough time to accrue a high enough overall career value. I picked the cutoff point as 2014, since, at the time, that meant that every player in the dataset had been drafted at least 10 seasons ago, which gave players enough time to rack up AV(approximate Value), which is Pro Football Reference’s take on WAR, or Wins Above Replacement, commonly seen in baseball. It is by no means perfect, but in a game like football where discerning a player’s lone contribution to the team is tricky to do, it is the best metric we have at our disposal. This left us with 9,647 players left to analyze.\nIt should also be noted that, for most of this analysis, I only included players who actually played a snap in the NFL. This removed almost 3000 more players from the dataset, leaving us with just over 6,500 obervations remaining.\n\n\nStandardizing wAV\nAs previously mentioned, I will be using PFR’s Weighted Approximate Value (wAV) metric to determine draft pick success. However, there are issues with this metric, and chief among them is the fact that not all positions accrue value at the same rate. For example, if a Center has an All-Pro caliber year, they will probably be worth somewhere around 16 AV. However, that number is routinely passed by 4-6 QB’s every year. Because of this, I decided to standardize every player’s wAV realative to their position. In doing this, we achieve what can be considered to be a more fair way of evaluating players across different positions. Here’s an example of how it works:\nPlayer X plays at a position where the average wAV for a player’s career was 5, and the standard deviation is 2. If player X’s wAV for his career is 9, then his standardized wAV would be 2.0, since his wAV is 4 higher than the average, which is 2 standard deviaitons.\nFor a real world example, Peyton Manning (QB) and Zach Thomas (LB) had a dispairty of over 60 wAV between their career totals(176 vs 115). Using just that stat, you would think that Manning was far and beyond the better player, but according to their position-weighted standardized values, they were of equal relative value, both being rated at 3.67 standard deviations above their positional average. This means that Manning was of similar value to QB’s as Thomas was to LB’s.\nNow, this still isn’t a perfect measurement of a player’s value. The main issue is that this metric tends to undervalue QB’s as opposed to overvaluing. This is because QB’s and other positions like TE that have a smaller pool of players to draw from, so outlier careers, such as Manning or Kelce, can significantly influence the overall mean for the position group. This explains why Rod Woodson, who was certainly one of the best DB’s to ever play, is rated as far and beyond the most valuable player in NFL history by this new metric; he was a great player who had a long career, and did so at a position that sees more players take snaps than any other, meaning the positional mean is very low. For the entire sample, there were 341 drafted QB’s who took a snap in the NFL, as opposed to 400 snap-taking DB’s… in the 80’s alone.\n\n\nDummy Variables\nNow that we have the position-agnostic swAV, or Standardized Weighted Approximate Value, we can create a set of dummy variables that can categorize a player’s career. It is worth noting that, as the graph below indicates, there is a serious skew towards numbers between 0 and -1.\n\nBecause of this, if we want to create these dummy variables, we will have to do so based on our perception of average roster construction, which isn’t an exact science. Nonetheless, here are the groupings we came up with:\n\nBad: less than -0.70\nBelow Average: -0.70 to -0.20\nAverage: -0.20 to 0.70\nAbove Average: 0.70 to 1.50\nGood: 1.5 to 2.5\nGreat: over 2.5\n\nThese partitions created this distribution, which we believe to be a fair assessment of the average NFL roster:\n\nNow that we have our new variables, we can finally dive into the analysis."
  },
  {
    "objectID": "projects/proj_1/index.html#impact-of-draft-success-on-winning",
    "href": "projects/proj_1/index.html#impact-of-draft-success-on-winning",
    "title": "NFL Draft Trends Analyzed and Visualized(Work In Progress)",
    "section": "Impact of Draft Success on Winning",
    "text": "Impact of Draft Success on Winning\nIn order to measure the correlation of draft success on team success, I took a team’s total winning percentage for a given decade(1980’s up to 2010’s) and compared it to that team’s average value for a draft pick over that same time, and these were the results:\n\nAs you can see, there certainly is a correlation there, but not quite as high as initially expected, with a moderate Pearson correlation coefficient of just 0.30. This makes some sense when considering that players are not solely acquired from the draft, NFL organizations can also acquire players through free agency or via trading, but still a lower positive relation than what was expected.\nAfter seeing these results, I thought that my initial process might have been unfairly punishing teams that accumulated more late round picks, a strategy that is overall good for team building, but greatly reduces the team’s average draft pick value. In order to get around this, I decided to run a similar test to the last, but this time only use a team’s top 5 picks from each draft, so that a team wouldn’t be punished for having more selections. Here were the results of that comparison:\n\nUltimately, there wasn’t much of a change in correlation with this comparison, with this graph having a Pearson R-squared of 0.36, a marginal upgrade over the previous. Despite the draft being the easiest and most common venue by which NFL team’s aquire players, there is nothing but a moderate correlation between their drafting success and on the field success."
  },
  {
    "objectID": "projects/proj_1/index.html#more-impactful-late-round-success-or-early-round-failure",
    "href": "projects/proj_1/index.html#more-impactful-late-round-success-or-early-round-failure",
    "title": "NFL Draft Trends Analyzed and Visualized(Work In Progress)",
    "section": "More Impactful: Late Round Success or Early Round Failure?",
    "text": "More Impactful: Late Round Success or Early Round Failure?\nWhile researching the success of the draft on overall success, I came across an interesting discovery: The correlation between rounds 4-12 success and winning percentage was actually higher than the correlation between rounds 1-3 drafting success and winning percentage. This was surprising for a number of reasons; Not only do high round picks often become much more impactful players than later round picks(32.9% of all players drafted 1-3 become at least Above Average, as oppose to just under 10% for players drafted 4-12), but most teams also take extra care to select the most talented player available in the early rounds, whereas later rounds often see teams “reach” for players that fill a position of need. In order to investigate this further, I decided to create a pair of new dummy variables:\n\nSteal\nA “steal” is defined as a player whose value exceeds that of their expectations as defined by their draft position. To quantify it, we have used our dummy variables from earlier to come up with this definition:\n\n“Great” in round 2 or later\n“Good” in round 3 or later\n“Above Average” in round 4 or later\n“Average” in round 5 or later\n\n\n\nWhiff\nA “whiff” is the antithesis of a steal, being a player whose value falls short of their expectations, specifically:\n\n“Average” in round 1\n“Below Average” in round 2\n“Bad” in round 3\n\nWith these new variables, we can compare the occurrence of these variables with the teams winning percentage to see which has a larger impact on a team’s success.\n\n\nFirst, we have impact of Whiffs on success:\n\n\n\nThen we have Steals on success:\n\nAs you can see from the whiffs graph, there is virtually no correlation between missing on early-round picks and games won. The r-squared value, which would be expected to have a negative relationship, actually shows a slight positive relationship of 0.07, so we can confidently say that missing on early round picks has little to no impact on success. While the steals graph may not look that much better, there is a far higher correlation of 0.41.\nThis test firmly states that finding solid but not spectacular players in later rounds helps winning more so than drafting mediocre or bad players with valuable early round picks hurts it. These results reinforce the idea that many football analysts have come around to in recent years: The notion that trading higher value picks away for more chance to select players with less valuable picks, as more selections gives you a greater chance to find a “diamond in the rough”, so to speak. In a world where many believe that predicting which college players will be good NFL players is far harder than most give it credit for, quantity of picks can be just as, if not more valuable than quality of picks."
  }
]